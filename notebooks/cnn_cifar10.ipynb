{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 CNN Experiments\n",
    "\n",
    "**|| Jonty Sinai ||** 11-04-2019\n",
    "\n",
    "So far we've managed to train a LeNet-5 CNN to get 98.68% test accuracy on MNIST. This is good because LeNet-5's architecture was designed specifically do well at the MNIST task. It's difficult to say why exactly this architecture works well on the MNIST dataset, only that experimental design most likely converged in that direction, particularly under the computing power constraints of 1998.\n",
    "\n",
    "However when we applied LeNet-5 to CIFAR-10 the results were still not great with a mediocre 51.64% test accuracy - only slighter better than the [feedforward neural network](neural_network.ipynb) trained earlier.\n",
    "\n",
    "In this notebook we will explore other CNN architectures to push the limits of how well we can do on CIFAR-10 under the following constrains:\n",
    "\n",
    "* only three epochs of training allowed,\n",
    "* on a CPU,\n",
    "* in less than ~10 minutes.\n",
    "\n",
    "This notebook will be purely experimental and objects will may be overwritten but as long as the notebook is followed sequentially, things should compute. This is a learning experience for me and I'll try my best to reason through my intuition for each progressive design choice taken in each experiment. \n",
    "\n",
    "Later I'll implement an experiment manager to take advantage of the configurable CNN architecture. That will allow for an automatic hyperparameter search under the constraints.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "### List of Experiments:\n",
    "\n",
    "1. [Add ReLU and MaxPool](#exp1)\n",
    "2. [Increase Hidden Channel Sizes](#exp2)\n",
    "3. [Reduce Convolution Parameters](#exp3)\n",
    "4. [Increase Fully Connected Parameters](#exp4)\n",
    "5. [Increase Number of Convolutional Layers](#exp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11dd348f0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "HOME = os.environ['AI_HOME']\n",
    "ROOT = os.path.join(HOME, 'artificial_neural_networks')\n",
    "DATA = os.path.join(ROOT, 'data')\n",
    "MNIST = os.path.join(DATA, 'mnist')\n",
    "CIFAR10 = os.path.join(DATA, 'cifar10')\n",
    "\n",
    "random.seed(1901)\n",
    "np.random.seed(1901)\n",
    "torch.manual_seed(1901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Module\n",
    "\n",
    "Once again we'll initallise the CNN module which takes an OrderedDict describing the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    # ref: https://discuss.pytorch.org/t/flatten-layer-of-pytorch-build-by-sequential-container/5983/3\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, arch_dict: OrderedDict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            arch_dict (OrderedDict) : Specifies the CNN archicture where\n",
    "                key, value pairs correspond to layer_type, layer_params.\n",
    "                Layer parameters are specified as a tuple of integers or\n",
    "                they can be None.\n",
    "                \n",
    "                The supported layer types with their parameters are:\n",
    "                \n",
    "                    Conv2d : (in_channels, out_channels, kernel_size, stride, padding)\n",
    "                    AvgPool2d : (kernel_size, stride, padding)\n",
    "                    MaxPool2d : (kernel_size, stride, padding)\n",
    "                    Flatten : None\n",
    "                    Linear : input_size, output_size\n",
    "                    ReLU : None\n",
    "                    Sigmoid : None\n",
    "                    Tanh : None\n",
    "                    \n",
    "                If more layer_types are used repeatedly, then they should be\n",
    "                post-fixed with an underscore followed by an alphanumeric\n",
    "                index. \n",
    "                \n",
    "                Eg: \"Conv2d_1\", \"Conv2d_2\", \"Tanh_1a\", \"Tanh_1b\"\n",
    "                    \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # make sure arch_dict is an OrderedDict\n",
    "        # for activation layers, use None for layer_params\n",
    "        for layer_type, layer_params in arch_dict.items():\n",
    "            \n",
    "            layer_type = re.sub(r\"_[\\d\\w]+\", \"\", layer_type) # remove number/letter post-fixing of layer types\n",
    "            \n",
    "            if layer_type == \"Conv2d\":\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
    "            elif layer_type == \"AvgPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.AvgPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"MaxPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.MaxPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"Flatten\":\n",
    "                self.layers.append(\n",
    "                    Flatten())\n",
    "            elif layer_type == \"Linear\":\n",
    "                input_size, output_size = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Linear(input_size, output_size))\n",
    "            elif layer_type == \"ReLU\":\n",
    "                self.layers.append(\n",
    "                    nn.ReLU())\n",
    "            elif layer_type == \"Sigmod\":\n",
    "                self.layers.append(\n",
    "                    nn.Sigmoid())\n",
    "            elif layer_type == \"Tanh\":\n",
    "                self.layers.append(\n",
    "                    nn.Tanh())\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, optimiser, loss_function, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1} \" + \"=\"*80 + \">\")\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(training_data):\n",
    "            images, labels = batch\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(images)\n",
    "            # backward pass\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            # print progress\n",
    "            \n",
    "            if (batch_idx + 1) % 1000 == 0:    # print every 1000 mini-batches\n",
    "                print(\"[%4d/6000] loss: %.3f\" %\n",
    "                      (batch_idx + 1, total_loss / 1000))\n",
    "                total_loss = 0.0\n",
    "                \n",
    "    print(\"Finished Training \" + \"=\"*71 + \">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            images, truth = data\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += truth.size(0)\n",
    "            correct += (predicted == truth).sum().item()\n",
    "\n",
    "    print('Test accuracy on %d test images: %.4f %%' % (total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transforms = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]  # note that we normalise by rank-1 tensors\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "cifar10_trainset = torchvision.datasets.CIFAR10(root=CIFAR10, train=True, download=True, transform=cifar10_transforms)\n",
    "cifar10_trainloader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=10, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "cifar10_testset = torchvision.datasets.CIFAR10(root=CIFAR10, train=False, download=True, transform=cifar10_transforms)\n",
    "cifar10_testloader = torch.utils.data.DataLoader(cifar10_testset, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8 - 2) / 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp1\"></a>\n",
    "## Experiment 1: ReLU and MaxPool\n",
    "\n",
    "- **Last Experiment:** LeNet-5\n",
    "- **Last Test Accuracy:** 51.64\n",
    "- **This Test Accuracy:** 63.39\n",
    "\n",
    "The first change we'll make to LeNet-5 is to replace AvgPool with MaxPool and Tanh with ReLU which are known to respectively perform better. This massively increases test accuracy by 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 10, 3, 1, 1)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (10, 16, 5, 1, 0)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (576, 120)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (120, 84)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_6', (84, 10))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 10, 3, 1, 1)  # Conv layer: 32x32x3 -> 32x32x16, kernel=3x3, stride=1, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (10, 16, 5, 1, 0)  # Conv layer: 16x16x16 -> 12x12x32, kernel=5x5, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 6x6x16 -> 576\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (576, 120) # FC layer: 400 input units -> 120 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (120, 84) # FC layer: 120 input units -> 84 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 6: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_6\"] = (84, 10) # FC layer: 84 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(10, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=576, out_features=120, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.824\n",
      "[2000/6000] loss: 1.545\n",
      "[3000/6000] loss: 1.443\n",
      "[4000/6000] loss: 1.378\n",
      "[5000/6000] loss: 1.338\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.249\n",
      "[2000/6000] loss: 1.209\n",
      "[3000/6000] loss: 1.193\n",
      "[4000/6000] loss: 1.160\n",
      "[5000/6000] loss: 1.139\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 1.083\n",
      "[2000/6000] loss: 1.080\n",
      "[3000/6000] loss: 1.071\n",
      "[4000/6000] loss: 1.046\n",
      "[5000/6000] loss: 1.036\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 63.3900 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp2\"></a>\n",
    "## Experiment 2: Increase Hidden Channel Sizes\n",
    "\n",
    "- **Last Experiment:** ReLU, MaxPool\n",
    "- **Last Test Accuracy:** 63.39\n",
    "- **This Test Accuracy:** 63.81\n",
    "\n",
    "The next set of changes is inspired by AlexNet, which achieved state of the art on ImageNet (a significantly harder task than CIFAR-10), shown below:\n",
    "\n",
    "<img src=\"./assets/alex_net.png\" width=\"800\">\n",
    "\n",
    "source: [Andrew Ng, Coursera](https://www.coursera.org/learn/convolutional-neural-networks/home/welcome)\n",
    "\n",
    "We won't be able to train a neural network as deep or with as many parameters as AlexNet, but we can try and come with an architecture similar to it on a smaller scale. Some design patterns to note:\n",
    "\n",
    "- AlexNet quickly reduces the resolution of the input images but widens the number of channels.\n",
    "- The number of channels is increased while the resolution is decreasesd progressively through the network.\n",
    "- Convolution kernel sizes start of larger, than become smaller.\n",
    "- Same padding is used between successive convolutional layers.\n",
    "\n",
    "We'll implement some of these ideas progressively through this notebook, starting with larger hidden channel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 18, 3, 1, 0)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (18, 32, 5, 1, 0)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (800, 256)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (256, 128)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_6', (128, 10))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 18, 3, 1, 0)  # Conv layer: 32x32x3 -> 30x30x18, kernel=3x3, stride=1, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (18, 32, 5, 1, 0)  # Conv layer: 15x15x10 -> 11x11x32, kernel=5x5, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 5x5x32 -> 800\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (800, 256) # FC layer: 800 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (256, 128) # FC layer: 256 input units -> 128 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 6: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_6\"] = (128, 10) # FC layer: 128 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(18, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=800, out_features=256, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.800\n",
      "[2000/6000] loss: 1.477\n",
      "[3000/6000] loss: 1.386\n",
      "[4000/6000] loss: 1.321\n",
      "[5000/6000] loss: 1.265\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.179\n",
      "[2000/6000] loss: 1.151\n",
      "[3000/6000] loss: 1.110\n",
      "[4000/6000] loss: 1.105\n",
      "[5000/6000] loss: 1.086\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 1.002\n",
      "[2000/6000] loss: 0.975\n",
      "[3000/6000] loss: 0.987\n",
      "[4000/6000] loss: 0.989\n",
      "[5000/6000] loss: 0.957\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 63.8100 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp3\"></a>\n",
    "## Experiment 3: Reduce Number of Convolutional Parameters\n",
    "\n",
    "- **Last Experiment:** Increase Hidden Channel Sizes\n",
    "- **Last Test Accuracy:** 63.81\n",
    "- **This Test Accuracy:** 65.19\n",
    "\n",
    "Here we take two steps to reduce the number of convolutional parameters, with only a slight increase in the number of fully connected parameters:\n",
    "\n",
    "- Reduce the number of hidden channels\n",
    "- Reduce the size of the second hidden kernel\n",
    "- To keep the size of the flat layer roughly the same we increase the stride by 1 for the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 18, 3, 2, 0)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 1, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (18, 24, 3, 1, 0)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (864, 256)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (256, 128)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_6', (128, 10))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 18, 3, 2, 0)  # Conv layer: 32x32x3 -> 15x15x24, kernel=3x3, stride=2, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 1, 0)  # followed by 2x2 MaxPool, stride = 1, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (18, 24, 3, 1, 0)  # Conv layer: 14x14x32 -> 12x12x32, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 6x6x24 -> 864\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (864, 256) # FC layer: 864 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (256, 128) # FC layer: 256 input units -> 128 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 6: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_6\"] = (128, 10) # FC layer: 128 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 18, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(18, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=864, out_features=256, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.794\n",
      "[2000/6000] loss: 1.476\n",
      "[3000/6000] loss: 1.367\n",
      "[4000/6000] loss: 1.295\n",
      "[5000/6000] loss: 1.236\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.146\n",
      "[2000/6000] loss: 1.133\n",
      "[3000/6000] loss: 1.101\n",
      "[4000/6000] loss: 1.076\n",
      "[5000/6000] loss: 1.065\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.974\n",
      "[2000/6000] loss: 0.985\n",
      "[3000/6000] loss: 0.969\n",
      "[4000/6000] loss: 0.966\n",
      "[5000/6000] loss: 0.920\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 65.1900 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp4\"></a>\n",
    "## Experiment 4: Increase Number of Fully Connected Parameters\n",
    "\n",
    "- **Last Experiment:** Reduce Number of Convolutional Parameters\n",
    "- **Last Test Accuracy:** 65.19\n",
    "- **This Test Accuracy:** 67.18\n",
    "\n",
    "In this experiment I wanted to see what would happen if I increased the number of fully connected parameters (inspired by the conventional thinking with fully connected networks). To increase the size of the flat layer I reduced the stride in the first convolutional layer while adding padding of 1 so that the resolution through the first layer is sustained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 18, 3, 1, 1)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (18, 24, 3, 1, 0)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (1176, 512)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (512, 256)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_6', (256, 10))])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 18, 3, 1, 1)  # Conv layer: 32x32x3 -> 32x32x18, kernel=3x3, stride=1, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (18, 24, 3, 1, 0)  # Conv layer: 16x16x18 -> 14x14x24, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 7x7x24 -> 1176\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (1176, 512) # FC layer: 1176 input units -> 512 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (512, 256) # FC layer: 512 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 6: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_6\"] = (256, 10) # FC layer: 256 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(18, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=1176, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.727\n",
      "[2000/6000] loss: 1.383\n",
      "[3000/6000] loss: 1.271\n",
      "[4000/6000] loss: 1.180\n",
      "[5000/6000] loss: 1.117\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.000\n",
      "[2000/6000] loss: 0.974\n",
      "[3000/6000] loss: 0.961\n",
      "[4000/6000] loss: 0.931\n",
      "[5000/6000] loss: 0.920\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.777\n",
      "[2000/6000] loss: 0.787\n",
      "[3000/6000] loss: 0.806\n",
      "[4000/6000] loss: 0.796\n",
      "[5000/6000] loss: 0.795\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 67.1800 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp5\"></a>\n",
    "## Experiment 5: Increase Number of Convolutional Layers\n",
    "\n",
    "- **Last Experiment:** Increase Number of Fully Connected Parameters\n",
    "- **Last Test Accuracy:** 67.18\n",
    "- **This Test Accuracy:** 68.51\n",
    "\n",
    "In this experiment I wanted to see what would happen if I increased the number of convolutional layers. \n",
    "\n",
    "The results appeared to be slightly worse, suggesting that a lot of the predictive power of the neural network lies in the dense layers. However, the conventional thinking is that the convolutional layers should increase the fidelity of our feature extraction so perhaps we can play around with those parameters a bit more in the next experiment. Nonethless Exp 5 is still an improvement over Exp 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 18, 3, 1, 1)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (18, 24, 3, 1, 1)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Conv2d_3', (24, 32, 3, 1, 1)),\n",
       "             ('ReLU_3a', None),\n",
       "             ('MaxPool2d_3', (2, 2, 0)),\n",
       "             ('ReLU_3b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (512, 256)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (256, 128)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_7', (128, 10))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 18, 3, 1, 1)  # Conv layer: 32x32x3 -> 32x32x18, kernel=3x3, stride=1, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (18, 24, 3, 1, 1)  # Conv layer: 16x16x18 -> 14x14x24, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_3\"] = (24, 32, 3, 1, 1)  # Conv layer: 16x16x18 -> 14x14x24, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_3a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_3\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_3b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 4x4x32 -> 512\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (512, 256) # FC layer: 1176 input units -> 512 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (256, 128) # FC layer: 512 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# # 6: Fully Connected Output Layer\n",
    "# cnn_arch[\"Linear_6\"] = (128, 128) # FC layer: 256 input units -> 128 output units\n",
    "# cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 7: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_7\"] = (128, 10) # FC layer: 128 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(18, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.790\n",
      "[2000/6000] loss: 1.503\n",
      "[3000/6000] loss: 1.380\n",
      "[4000/6000] loss: 1.267\n",
      "[5000/6000] loss: 1.163\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.089\n",
      "[2000/6000] loss: 1.051\n",
      "[3000/6000] loss: 1.021\n",
      "[4000/6000] loss: 0.998\n",
      "[5000/6000] loss: 0.965\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.872\n",
      "[2000/6000] loss: 0.870\n",
      "[3000/6000] loss: 0.869\n",
      "[4000/6000] loss: 0.868\n",
      "[5000/6000] loss: 0.844\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 68.5100 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp6\"></a>\n",
    "## Experiment 6: More Convolutional Layers with More Fully Connected Parameters\n",
    "\n",
    "- **Last Experiment:** More Convolutional Layers\n",
    "- **Last Test Accuracy:** 68.51%\n",
    "- **This Test Accuracy:** 69.07%\n",
    "\n",
    "In [Exp 4](#exp4) an increase in the number of fully connected parameters increased our accuracy w.r.t [Exp 3](#exp3), while in [Exp 5](#exp5) an increase in the number of convolutional layers increased accuracy w.r.t Exp 3 but not 4. Here we combine the effects for an overal improvement over 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 24, 3, 1, 1)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (24, 32, 3, 1, 1)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Conv2d_3', (32, 64, 3, 1, 1)),\n",
       "             ('ReLU_3a', None),\n",
       "             ('MaxPool2d_3', (2, 2, 0)),\n",
       "             ('ReLU_3b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (1024, 512)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (512, 256)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_7', (256, 10))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 24, 3, 1, 1)  # Conv layer: 32x32x3 -> 16x16x24, kernel=5x5, stride=2, padding=2\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 1, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (24, 32, 3, 1, 1)  # Conv layer: 16x16x24 -> 16x16x32, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_3\"] = (32, 64, 3, 1, 1)  # Conv layer: 8x8x64 -> 8x8x32, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_3a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_3\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_3b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 4x4x64 -> 1024\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (1024, 512) # FC layer: 1024 input units -> 512 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (512, 256) # FC layer: 512 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# # 6: Fully Connected Output Layer\n",
    "# cnn_arch[\"Linear_6\"] = (128, 128) # FC layer: 256 input units -> 128 output units\n",
    "# cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 7: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_7\"] = (256, 10) # FC layer: 128 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.769\n",
      "[2000/6000] loss: 1.440\n",
      "[3000/6000] loss: 1.313\n",
      "[4000/6000] loss: 1.196\n",
      "[5000/6000] loss: 1.126\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.034\n",
      "[2000/6000] loss: 0.993\n",
      "[3000/6000] loss: 0.963\n",
      "[4000/6000] loss: 0.931\n",
      "[5000/6000] loss: 0.938\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.802\n",
      "[2000/6000] loss: 0.816\n",
      "[3000/6000] loss: 0.822\n",
      "[4000/6000] loss: 0.805\n",
      "[5000/6000] loss: 0.807\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 69.0700 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp7\"></a>\n",
    "## Experiment 7: Even More Fully Connected Parameters\n",
    "\n",
    "- **Last Experiment:** More Convolutional Layers with More Fully Connected Parameters\n",
    "- **Last Test Accuracy:** 69.07%\n",
    "- **This Test Accuracy:** 67.64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 12, 3, 1, 1)),\n",
       "             ('ReLU_1a', None),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1b', None),\n",
       "             ('Conv2d_2', (12, 24, 3, 1, 1)),\n",
       "             ('ReLU_2a', None),\n",
       "             ('MaxPool2d_2', (2, 2, 0)),\n",
       "             ('ReLU_2b', None),\n",
       "             ('Flatten_3', None),\n",
       "             ('Linear_4', (1536, 512)),\n",
       "             ('ReLU_4', None),\n",
       "             ('Linear_5', (512, 256)),\n",
       "             ('ReLU_5', None),\n",
       "             ('Linear_6', (256, 10))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_1\"] = (3, 12, 3, 1, 1)  # Conv layer: 32x32x3 -> 32x32x18, kernel=3x3, stride=1, padding=1\n",
    "cnn_arch[\"ReLU_1a\"] = None  # followed by relu nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_1b\"] = None  # followed by relu nonlinear activation\n",
    "# 2: Convolutional Layer\n",
    "cnn_arch[\"Conv2d_2\"] = (12, 24, 3, 1, 1)  # Conv layer: 16x16x18 -> 14x14x24, kernel=3x3, stride=1, padding=0\n",
    "cnn_arch[\"ReLU_2a\"] = None  # followed by tanh nonlinear activation\n",
    "cnn_arch[\"MaxPool2d_2\"] = (2, 2, 0)  # followed by 2x2 MaxPool, stride = 2, padding=0\n",
    "cnn_arch[\"ReLU_2b\"] = None  # followed by tanh nonlinear activation\n",
    "# 3: Flatten\n",
    "cnn_arch[\"Flatten_3\"] = None # flatten 8x8x24 -> 1536\n",
    "# 4: Fully Connected Layer\n",
    "cnn_arch[\"Linear_4\"] = (1536, 512) # FC layer: 1176 input units -> 512 output units\n",
    "cnn_arch[\"ReLU_4\"] = None  # followed by tanh nonlinear activation\n",
    "# 5: Fully Connected Layer\n",
    "cnn_arch[\"Linear_5\"] = (512, 256) # FC layer: 512 input units -> 256 output units\n",
    "cnn_arch[\"ReLU_5\"] = None  # followed by tanh nonlinear activation\n",
    "# 6: Fully Connected Output Layer\n",
    "cnn_arch[\"Linear_6\"] = (256, 10) # FC layer: 256 input units -> 10 output units\n",
    "\n",
    "cnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=1536, out_features=512, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(cnn_arch)\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = cnn(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.716\n",
      "[2000/6000] loss: 1.400\n",
      "[3000/6000] loss: 1.266\n",
      "[4000/6000] loss: 1.193\n",
      "[5000/6000] loss: 1.140\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.004\n",
      "[2000/6000] loss: 1.015\n",
      "[3000/6000] loss: 0.973\n",
      "[4000/6000] loss: 0.957\n",
      "[5000/6000] loss: 0.941\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.800\n",
      "[2000/6000] loss: 0.816\n",
      "[3000/6000] loss: 0.800\n",
      "[4000/6000] loss: 0.802\n",
      "[5000/6000] loss: 0.822\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(cnn, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 67.6400 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (axiom)",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
