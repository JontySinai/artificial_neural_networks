{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Tensor Batching with PyTorch\n",
    "\n",
    "**|| Jonty Sinai ||** 30-04-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5098118670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1901)\n",
    "np.random.seed(1901)\n",
    "torch.manual_seed(1901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Batch of Input-Target Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([1, 1, 1]), tensor([1, 1, 1, 1])),\n",
       " (tensor([2, 2, 2, 2, 2]), tensor([2, 2, 2, 2])),\n",
       " (tensor([3, 3]), tensor([3, 3, 3])),\n",
       " (tensor([4, 4, 4]), tensor([4, 4, 4])),\n",
       " (tensor([5, 5, 5, 5]), tensor([5, 5, 5, 5, 5]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (input_tensor, target_tensor) 1-to-1 correspondence\n",
    "batch = [(torch.tensor([1, 1, 1]), torch.tensor([1, 1, 1, 1])), \n",
    "         (torch.tensor([2, 2, 2, 2, 2]), torch.tensor([ 2,  2, 2,  2])), \n",
    "         (torch.tensor([3, 3]), torch.tensor([3, 3,  3])), \n",
    "         (torch.tensor([4, 4, 4]), torch.tensor([ 4, 4, 4])), \n",
    "         (torch.tensor([5, 5, 5, 5]), torch.tensor([ 5, 5, 5,  5,  5]))]\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input: original\n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 4, 5],\n",
      "        [0, 2, 0, 0, 5],\n",
      "        [0, 2, 0, 0, 0]])\n",
      "\n",
      "Padded target: original\n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 0, 5],\n",
      "        [0, 0, 0, 0, 5]])\n"
     ]
    }
   ],
   "source": [
    "input_, target = zip(*batch)\n",
    "\n",
    "input_orig = rnn_utils.pad_sequence(input_)\n",
    "target_orig = rnn_utils.pad_sequence(target)\n",
    "\n",
    "print('Padded input: original\\n')\n",
    "print(input_orig)\n",
    "print('\\nPadded target: original\\n')\n",
    "print(target_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Sort Input Independently and Resort Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "lengths = torch.tensor([len(seq) for seq in input_], dtype=torch.long)\n",
    "\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "sorted_lengths, sort_idx = lengths.sort(descending=True)\n",
    "\n",
    "print(sort_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input: sorted\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 0],\n",
      "        [2, 5, 0, 0, 0],\n",
      "        [2, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "max_length = sorted_lengths[0].item()\n",
    "\n",
    "# I use sequence first batching, so use repeat to index consistently across each time step\n",
    "input_sorted = input_orig.gather(dim=1, index=sort_idx.repeat(max_length, 1))\n",
    "\n",
    "print('Padded input: sorted\\n')\n",
    "print(input_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([2, 5, 1, 4, 3, 2, 5, 1, 4, 3, 2, 5, 1, 4, 2, 5, 2]), batch_sizes=tensor([5, 5, 4, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "input_packed = rnn_utils.pack_padded_sequence(input_sorted, sorted_lengths)\n",
    "\n",
    "print(input_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input: unpacked\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 0],\n",
      "        [2, 5, 0, 0, 0],\n",
      "        [2, 0, 0, 0, 0]])\n",
      "\n",
      "Padded target: misaligned\n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 0, 5],\n",
      "        [0, 0, 0, 0, 5]])\n"
     ]
    }
   ],
   "source": [
    "input_unpacked, _ = rnn_utils.pad_packed_sequence(input_packed) # suppose this has been transformed\n",
    "\n",
    "print('Padded input: unpacked\\n')\n",
    "print(input_unpacked)\n",
    "print('\\nPadded target: misaligned\\n')\n",
    "print(target_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# this is a neat trick I found which will map each sequence in the unpacked batch to the original location\n",
    "# the argsort of the argsort is the original index\n",
    "_, orig_idx = sort_idx.sort()\n",
    "\n",
    "print(orig_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input: restored\n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 4, 5],\n",
      "        [0, 2, 0, 0, 5],\n",
      "        [0, 2, 0, 0, 0]])\n",
      "\n",
      "Padded target: aligned\n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 0, 5],\n",
      "        [0, 0, 0, 0, 5]])\n"
     ]
    }
   ],
   "source": [
    "# use the same trick with repeat to consistently index each time step\n",
    "input_restored = input_unpacked.gather(dim=1, index=orig_idx.repeat(max_length, 1))\n",
    "\n",
    "print('Padded input: restored\\n')\n",
    "print(input_restored)\n",
    "print('\\nPadded target: aligned\\n')\n",
    "print(target_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(input_restored, input_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Just Sort the Input and Targets Together\n",
    "\n",
    "Since we will process the targets sequentially we can just sort the targets by the input lengths. The decoder won't care which sequence it sees first in the batch, only that the target sequences are correctly aligned to the encoder outputs batchwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([2, 2, 2, 2, 2]), tensor([2, 2, 2, 2])),\n",
       " (tensor([5, 5, 5, 5]), tensor([5, 5, 5, 5, 5])),\n",
       " (tensor([1, 1, 1]), tensor([1, 1, 1, 1])),\n",
       " (tensor([4, 4, 4]), tensor([4, 4, 4])),\n",
       " (tensor([3, 3]), tensor([3, 3, 3]))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_batch = sorted(batch, key=lambda b: len(b[0]), reverse=True)\n",
    "sorted_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input: presorted\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 0],\n",
      "        [2, 5, 0, 0, 0],\n",
      "        [2, 0, 0, 0, 0]])\n",
      "\n",
      "Padded target: presorted\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 0, 0],\n",
      "        [0, 5, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "input_presorted, target_presorted = zip(*sorted_batch)\n",
    "\n",
    "presorted_lengths = torch.tensor([len(seq) for seq in input_presorted])\n",
    "\n",
    "padded_input_presorted = nn.utils.rnn.pad_sequence(input_presorted)\n",
    "padded_target_presorted = nn.utils.rnn.pad_sequence(target_presorted)\n",
    "\n",
    "print('Padded input: presorted\\n')\n",
    "print(padded_input_presorted)\n",
    "print('\\nPadded target: presorted\\n')\n",
    "print(padded_target_presorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([2, 5, 1, 4, 3, 2, 5, 1, 4, 3, 2, 5, 1, 4, 2, 5, 2]), batch_sizes=tensor([5, 5, 4, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "packed_input_presorted = rnn_utils.pack_padded_sequence(padded_input_presorted, presorted_lengths)\n",
    "\n",
    "print(packed_input_presorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As far as the recurrent unit is concerned, it's input is unchanged\n",
    "torch.eq(rnn_utils.pad_packed_sequence(packed_input_presorted)[0], \n",
    "         rnn_utils.pad_packed_sequence(input_packed)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presorted input: unpacked\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 0],\n",
      "        [2, 5, 0, 0, 0],\n",
      "        [2, 0, 0, 0, 0]])\n",
      "\n",
      "Presorted target: aligned\n",
      "\n",
      "tensor([[2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 4, 3],\n",
      "        [2, 5, 1, 0, 0],\n",
      "        [0, 5, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "unpacked_input_presorted, _ = rnn_utils.pad_packed_sequence(packed_input_presorted) # suppose this has been transformed\n",
    "\n",
    "print('Presorted input: unpacked\\n')\n",
    "print(unpacked_input_presorted)\n",
    "print('\\nPresorted target: aligned\\n')\n",
    "print(padded_target_presorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (axiom)\n",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
