{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Network Experiments in PyTorch\n",
    "\n",
    "**|| Jonty Sinai ||** 13-04-2019\n",
    "\n",
    "To date, ResNet is one of the most successful neural network architectures in computer vision. Using what's called a skip connection, ResNet controls vanishing gradients and allows information to be propagated through relatively deeper layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f4c12e6d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re  # we'll use this later to process layer type keys in an OrderedDict \n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "HOME = os.environ['AI_HOME']\n",
    "ROOT = os.path.join(HOME, 'artificial_neural_networks')\n",
    "DATA = os.path.join(ROOT, 'data')\n",
    "MNIST = os.path.join(DATA, 'mnist')\n",
    "CIFAR10 = os.path.join(DATA, 'cifar10')\n",
    "\n",
    "random.seed(1901)\n",
    "np.random.seed(1901)\n",
    "torch.manual_seed(1901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Residual Networks\n",
    "\n",
    "The key idea behind ResNet is to observe that if we have two networks, a shallow network and its deeper counterpart, then the deeper network should perform no worse than the shallower network if the additional layers are identity mappings from the input. \n",
    "\n",
    "In particular (and as outlined in the paper referenced below) let this mapping, called the _residual mapping_, be denoted by $\\mathcal{H}(x)$. Then since the shallower network, let's denote it by $\\mathcal{F}(x)$ differs from the residual network by the identity we have:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{F}(x) = \\mathcal{H}(x) - x\n",
    "\\end{align}\n",
    "\n",
    "Now we can learn the deeper network instead:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{H}(x) = \\mathcal{F}(x) + x\n",
    "\\end{align}\n",
    "\n",
    "The picture looks something like this\n",
    "\n",
    "<img src=\"./assets/resnet_skip_connection.png\" width=\"300\">\n",
    "\n",
    "source: [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, _Deep Residual Learning for Image Recognition_, 2015](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "So how does this help solve the vanishing gradient problem? Well let's suppose that the network with mapping $\\mathcal{F}$ suffers from weight degradation, so that the input is mapped to approximately zero, then:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{F}(x) \\approx 0 \\ , \\ \\ \\lVert \\mathcal{F}(x) - x \\rVert \\approx x\n",
    "\\end{align}\n",
    "\n",
    "This means that the residual network, $\\mathcal{H}$ can be used to \"reset\" the input if $\\mathcal{F}$ has degraded:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{H}(x) \\approx x\n",
    "\\end{align}\n",
    "\n",
    "With this in mind, suppose that we have stacks of such residual networks, called _residual blocks_, mapping into each other:\n",
    "\n",
    "\\begin{align}\n",
    "x \\rightarrow \\mathcal{H}_1 \\rightarrow \\mathcal{H}_2 \\cdots \\rightarrow \\mathcal{H}_L \\rightarrow y\n",
    "\\end{align}\n",
    "\n",
    "Then if any one of these intermediate blocks degrades, then its input will simply be reset and passed onto the next block. This allows information to be propagated through a deep network even if weights decay.\n",
    "\n",
    "An example of these stacked blocks look and map to the output is shown below:\n",
    "\n",
    "<img src=\"./assets/resnet_architectures.png\" width=\"800\">\n",
    "\n",
    "source: [Andrew Ng, Coursera](https://www.coursera.org/learn/convolutional-neural-networks/home/welcome)\n",
    "\n",
    "Notice how ResNet only uses two pooling layers, once at the start and once after the last residual block.\n",
    "\n",
    "## Residual Block\n",
    "\n",
    "We will see how we can improve on CIFAR-10 using a simple architecture with two resnet blocks. A key implementation detail is that both $x, \\mathcal{F}(x) \\in \\mathbb{R}^d$ so that we can add them. This means that all convolutional layers will need same padding and the same number of intermediate channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size, num_channels, depth, stride=1, input_size=None):\n",
    "        super().__init__()\n",
    "        # same padding calculation\n",
    "        if stride > 1:\n",
    "            if input_size is None:\n",
    "                raise ValueError(\"input size is needed to calculate same padding when stride > 1\")\n",
    "            same_padding = round((kernel_size + (stride - 1) * input_size - stride) / 2)\n",
    "        else:\n",
    "            same_padding = round((kernel_size - 1) / 2)\n",
    "        # successive convolutions\n",
    "        self.convolution_block = nn.ModuleList(\n",
    "            [nn.Conv2d(num_channels, num_channels, kernel_size, stride, same_padding) for _ in range(depth)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = x.clone()\n",
    "        for convolution in self.convolution_block:\n",
    "            h = F.relu(convolution(h))\n",
    "        return h + x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test: ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResBlock(\n",
      "  (convolution_block): ModuleList(\n",
      "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(6, 6))\n",
      "    (1): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(6, 6))\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(6, 6))\n",
      "    (3): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(6, 6))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "res_block = ResBlock(kernel_size=3,\n",
    "                     num_channels=3,\n",
    "                     depth=4, \n",
    "                     stride=2,\n",
    "                     input_size=10)\n",
    "\n",
    "print(res_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3, 10, 10)\n",
    "\n",
    "z = res_block(x)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple ResNet\n",
    "\n",
    "Now let's implement a simple ResNet for CIFAR-10 which contains an initial convolution layer with max pooling for dimension reduction and channel expansion, two shallow residual blocks, followed by an average pooling layer and finally a fully connected layer mapping to the output.\n",
    "\n",
    "We'll use the same generic [`ConvNet`](conv_net.ipynb) module as before, but this time we'll add a `\"ResBlock\"` option and allow only the `\"ReLU\"` nonlinear activation. For simplicity we'll also restrict ResBlock strides to 1 so that the input size is not needed to calculate same padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    # ref: https://discuss.pytorch.org/t/flatten-layer-of-pytorch-build-by-sequential-container/5983/3\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, arch_dict: OrderedDict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            arch_dict (OrderedDict) : Specifies the CNN archicture where\n",
    "                key, value pairs correspond to layer_type, layer_params.\n",
    "                Layer parameters are specified as a tuple of integers or\n",
    "                they can be None.\n",
    "                \n",
    "                The supported layer types with their parameters are:\n",
    "                \n",
    "                    Conv2d : (in_channels, out_channels, kernel_size, stride, padding)\n",
    "                    AvgPool2d : (kernel_size, stride, padding)\n",
    "                    MaxPool2d : (kernel_size, stride, padding)\n",
    "                    ResBlock : (kernel_size, num_channels, depth)\n",
    "                    Flatten : None\n",
    "                    Linear : input_size, output_size\n",
    "                    ReLU : None\n",
    "                    \n",
    "                If more layer_types are used repeatedly, then they should be\n",
    "                post-fixed with an underscore followed by an alphanumeric\n",
    "                index. \n",
    "                \n",
    "                Eg: \"Conv2d_1\", \"Conv2d_2\", \"Tanh_1a\", \"Tanh_1b\"\n",
    "                    \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # make sure arch_dict is an OrderedDict\n",
    "        # for activation layers, use None for layer_params\n",
    "        for layer_type, layer_params in arch_dict.items():\n",
    "            \n",
    "            layer_type = re.sub(r\"_[\\d\\w]+\", \"\", layer_type) # remove number/letter post-fixing of layer types\n",
    "            \n",
    "            if layer_type == \"Conv2d\":\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
    "            elif layer_type == \"AvgPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.AvgPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"MaxPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.MaxPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"ResBlock\":\n",
    "                kernel_size, num_channels, depth = layer_params\n",
    "                self.layers.append(\n",
    "                    ResBlock(kernel_size, num_channels, depth=depth))\n",
    "            elif layer_type == \"Flatten\":\n",
    "                self.layers.append(\n",
    "                    Flatten())\n",
    "            elif layer_type == \"Linear\":\n",
    "                input_size, output_size = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Linear(input_size, output_size))\n",
    "            elif layer_type == \"ReLU\":\n",
    "                self.layers.append(\n",
    "                    nn.ReLU())\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test: Simple ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 16, 3, 1, 1)),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1', None),\n",
       "             ('ResBlock_2', (3, 16, 2)),\n",
       "             ('Conv2d_3', (16, 32, 1, 1, 0)),\n",
       "             ('MaxPool2d_3', (2, 2, 0)),\n",
       "             ('ReLU_3', None),\n",
       "             ('ResBlock_4', (3, 32, 2)),\n",
       "             ('AvgPool2d_5', (2, 2, 0)),\n",
       "             ('Flatten_6', None),\n",
       "             ('Linear', (512, 10))])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional layer\n",
    "res_arch[\"Conv2d_1\"] = (3, 16, 3, 1, 1)  # 32x32x3 -> 32x32x16, 3x3 kernel, stride=1, padding=1\n",
    "res_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # 32x32x16 -> 16x16x16, 2x2 kernel, stride=2, padding = 0\n",
    "res_arch[\"ReLU_1\"] = None\n",
    "# 2: ResBlock\n",
    "res_arch[\"ResBlock_2\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 3: Convolutional layer\n",
    "res_arch[\"Conv2d_3\"] = (16, 32, 1, 1, 0)  # 16x16x16 -> 16x16x32, 1x1 kernel, stride=1, padding=0\n",
    "res_arch[\"MaxPool2d_3\"] = (2, 2, 0)  # 16x16x32 -> 8x8x32, 2x2 kernel, stride=2, padding = 0\n",
    "res_arch[\"ReLU_3\"] = None\n",
    "# 4: ResBlock\n",
    "res_arch[\"ResBlock_4\"] = (3, 32, 2) # 3x3 kernels, 32 channels, 2 layers\n",
    "# 5: AvgPool\n",
    "res_arch[\"AvgPool2d_5\"] = (2, 2, 0) # 8x8x32 -> 4x4x32, 2x2 kernel, stride=2, padding = 0\n",
    "# 6: Flatten\n",
    "res_arch[\"Flatten_6\"] = None  # 4x4x32 -> 512\n",
    "# 7: Fully Connected Layer\n",
    "res_arch[\"Linear\"] = (512, 10) # 512 hidden units -> 10 output units\n",
    "\n",
    "res_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "    (7): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (9): Flatten()\n",
      "    (10): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "res_small = ConvNet(res_arch)\n",
    "\n",
    "print(res_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = res_small(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, optimiser, loss_function, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1} \" + \"=\"*80 + \">\")\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(training_data):\n",
    "            images, labels = batch\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(images)\n",
    "            # backward pass\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            # print progress\n",
    "            \n",
    "            if (batch_idx + 1) % 1000 == 0:    # print every 1000 mini-batches\n",
    "                print(\"[%4d/6000] loss: %.3f\" %\n",
    "                      (batch_idx + 1, total_loss / 1000))\n",
    "                total_loss = 0.0\n",
    "                \n",
    "    print(\"Finished Training \" + \"=\"*71 + \">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            images, truth = data\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += truth.size(0)\n",
    "            correct += (predicted == truth).sum().item()\n",
    "\n",
    "    print('Test accuracy on %d test images: %.4f %%' % (total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_transforms = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]  # note that we normalise by rank-1 tensors\n",
    "                )\n",
    "\n",
    "# Training Set\n",
    "cifar10_trainset = torchvision.datasets.CIFAR10(root=CIFAR10, train=True, download=True, transform=cifar10_transforms)\n",
    "cifar10_trainloader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=10, shuffle=True, num_workers=0)\n",
    "\n",
    "# Test Set\n",
    "cifar10_testset = torchvision.datasets.CIFAR10(root=CIFAR10, train=False, download=False, transform=cifar10_transforms)\n",
    "cifar10_testloader = torch.utils.data.DataLoader(cifar10_testset, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "cifar10_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(res_small.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.788\n",
      "[2000/6000] loss: 1.459\n",
      "[3000/6000] loss: 1.373\n",
      "[4000/6000] loss: 1.309\n",
      "[5000/6000] loss: 1.263\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.191\n",
      "[2000/6000] loss: 1.167\n",
      "[3000/6000] loss: 1.141\n",
      "[4000/6000] loss: 1.110\n",
      "[5000/6000] loss: 1.080\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 1.037\n",
      "[2000/6000] loss: 1.020\n",
      "[3000/6000] loss: 0.998\n",
      "[4000/6000] loss: 1.005\n",
      "[5000/6000] loss: 0.972\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(res_small, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 64.4800 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(res_small, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrected Implementation of ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size, num_channels, depth, stride=1, input_size=None):\n",
    "        super().__init__()\n",
    "        # same padding calculation\n",
    "        if stride > 1:\n",
    "            if input_size is None:\n",
    "                raise ValueError(\"input size is needed to calculate same padding when stride > 1\")\n",
    "            same_padding = round((kernel_size + (stride - 1) * input_size - stride) / 2)\n",
    "        else:\n",
    "            same_padding = round((kernel_size - 1) / 2)\n",
    "        # successive convolutions\n",
    "        self.convolution_block = nn.ModuleList(\n",
    "            [nn.Conv2d(num_channels, num_channels, kernel_size, stride, same_padding) for _ in range(depth)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = x.clone()\n",
    "        for convolution in self.convolution_block[:-1]:\n",
    "            h = F.relu(convolution(h))\n",
    "        # don't apply relu to last convolution in block\n",
    "        h = self.convolution_block[-1](h)\n",
    "        # add and then apply relu\n",
    "        return F.relu(h + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "    (7): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (9): Flatten()\n",
      "    (10): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "res_small = ConvNet(res_arch)\n",
    "\n",
    "print(res_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = res_small(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(res_small.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.791\n",
      "[2000/6000] loss: 1.488\n",
      "[3000/6000] loss: 1.370\n",
      "[4000/6000] loss: 1.302\n",
      "[5000/6000] loss: 1.224\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.155\n",
      "[2000/6000] loss: 1.120\n",
      "[3000/6000] loss: 1.116\n",
      "[4000/6000] loss: 1.084\n",
      "[5000/6000] loss: 1.050\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.996\n",
      "[2000/6000] loss: 0.977\n",
      "[3000/6000] loss: 0.986\n",
      "[4000/6000] loss: 0.957\n",
      "[5000/6000] loss: 0.937\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(res_small, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 66.4600 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(res_small, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockTransition(nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size, in_channels, out_channels, depth):\n",
    "        super().__init__()\n",
    "        # padding calculation\n",
    "        padding = round((kernel_size - 1) / 2)\n",
    "        # convolution layers\n",
    "        # first layer changes number of channels and halves output size\n",
    "        self.convolution_block = nn.ModuleList(\n",
    "            [nn.Conv2d(in_channels, out_channels, kernel_size, 2, padding)])\n",
    "        # remaining layers preserve number of channels\n",
    "        self.convolution_block.extend(\n",
    "            [nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding) for _ in range(depth - 1)])\n",
    "        # transition convolution\n",
    "        self.transition = nn.Conv2d(in_channels, out_channels, 1, 2, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = x.clone()\n",
    "        for convolution in self.convolution_block[:-1]:\n",
    "            h = F.relu(convolution(h))\n",
    "        # don't apply relu to last convolution in block\n",
    "        h = self.convolution_block[-1](h)\n",
    "        # transition input through a 1x1 convolution kernel to change channel sizes and half resolution\n",
    "        x = self.transition(x)\n",
    "        return F.relu(h + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test: ResBlockTransition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResBlockTransition(\n",
      "  (convolution_block): ModuleList(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (transition): Conv2d(3, 6, kernel_size=(1, 1), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "res_block = ResBlockTransition(\n",
    "                     kernel_size=3,\n",
    "                     in_channels=3,\n",
    "                     out_channels=6,\n",
    "                     depth=4)\n",
    "\n",
    "print(res_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3, 10, 10)\n",
    "\n",
    "z = res_block(x)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with automatic transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, arch_dict: OrderedDict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            arch_dict (OrderedDict) : Specifies the CNN archicture where\n",
    "                key, value pairs correspond to layer_type, layer_params.\n",
    "                Layer parameters are specified as a tuple of integers or\n",
    "                they can be None.\n",
    "                \n",
    "                The supported layer types with their parameters are:\n",
    "                \n",
    "                    Conv2d : (in_channels, out_channels, kernel_size, stride, padding)\n",
    "                    AvgPool2d : (kernel_size, stride, padding)\n",
    "                    MaxPool2d : (kernel_size, stride, padding)\n",
    "                    ResBlock : (kernel_size, num_channels, depth)\n",
    "                    ResBlockTransition : (kernel_size, in_channels, out_channels, depth)\n",
    "                    Flatten : None\n",
    "                    Linear : input_size, output_size\n",
    "                    ReLU : None\n",
    "                    \n",
    "                If more layer_types are used repeatedly, then they should be\n",
    "                post-fixed with an underscore followed by an alphanumeric\n",
    "                index. \n",
    "                \n",
    "                Eg: \"Conv2d_1\", \"Conv2d_2\", \"ReLU_1a\", \"ReLU_1b\"\n",
    "                    \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # make sure arch_dict is an OrderedDict\n",
    "        # for activation layers, use None for layer_params\n",
    "        for layer_type, layer_params in arch_dict.items():\n",
    "            \n",
    "            layer_type = re.sub(r\"_[\\d\\w]+\", \"\", layer_type) # remove number/letter post-fixing of layer types\n",
    "            \n",
    "            if layer_type == \"Conv2d\":\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
    "            elif layer_type == \"AvgPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.AvgPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"MaxPool2d\":\n",
    "                kernel_size, stride, padding = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.MaxPool2d(kernel_size, stride, padding))\n",
    "            elif layer_type == \"ResBlock\":\n",
    "                kernel_size, num_channels, depth = layer_params\n",
    "                self.layers.append(\n",
    "                    ResBlock(kernel_size, num_channels, depth=depth))\n",
    "            elif layer_type == \"ResBlockTransition\":\n",
    "                kernel_size, in_channels, out_channels, depth = layer_params\n",
    "                self.layers.append(\n",
    "                    ResBlockTransition(kernel_size, in_channels, out_channels, depth=depth))\n",
    "            elif layer_type == \"Flatten\":\n",
    "                self.layers.append(\n",
    "                    Flatten())\n",
    "            elif layer_type == \"Linear\":\n",
    "                input_size, output_size = layer_params\n",
    "                self.layers.append(\n",
    "                    nn.Linear(input_size, output_size))\n",
    "            elif layer_type == \"ReLU\":\n",
    "                self.layers.append(\n",
    "                    nn.ReLU())\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 16, 3, 1, 1)),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1', None),\n",
       "             ('ResBlock_2', (3, 16, 2)),\n",
       "             ('ResBlockTransition_3', (3, 16, 32, 2)),\n",
       "             ('AvgPool2d_4', (2, 2, 0)),\n",
       "             ('Flatten_5', None),\n",
       "             ('Linear', (512, 10))])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional layer\n",
    "res_arch[\"Conv2d_1\"] = (3, 16, 3, 1, 1)  # 32x32x3 -> 32x32x16, 3x3 kernel, stride=1, padding=1\n",
    "res_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # 32x32x16 -> 16x16x16, 2x2 kernel, stride=2, padding = 0\n",
    "res_arch[\"ReLU_1\"] = None\n",
    "# 2: ResBlock\n",
    "res_arch[\"ResBlock_2\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 3: ResBlock\n",
    "res_arch[\"ResBlockTransition_3\"] = (3, 16, 32, 2) # 3x3 kernels, 32 channels, 2 layers\n",
    "# 4: AvgPool\n",
    "res_arch[\"AvgPool2d_4\"] = (2, 2, 0) # 8x8x32 -> 4x4x32, 2x2 kernel, stride=2, padding = 0\n",
    "# 5: Flatten\n",
    "res_arch[\"Flatten_5\"] = None  # 4x4x32 -> 512\n",
    "# 6: Fully Connected Layer\n",
    "res_arch[\"Linear\"] = (512, 10) # 512 hidden units -> 10 output units\n",
    "\n",
    "res_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlockTransition(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (transition): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Flatten()\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "res_small = ConvNet(res_arch)\n",
    "\n",
    "print(res_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = res_small(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(res_small.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.751\n",
      "[2000/6000] loss: 1.434\n",
      "[3000/6000] loss: 1.340\n",
      "[4000/6000] loss: 1.264\n",
      "[5000/6000] loss: 1.201\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.121\n",
      "[2000/6000] loss: 1.101\n",
      "[3000/6000] loss: 1.070\n",
      "[4000/6000] loss: 1.038\n",
      "[5000/6000] loss: 1.010\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.967\n",
      "[2000/6000] loss: 0.957\n",
      "[3000/6000] loss: 0.930\n",
      "[4000/6000] loss: 0.954\n",
      "[5000/6000] loss: 0.901\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(res_small, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 68.2100 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(res_small, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 16, 3, 1, 1)),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1', None),\n",
       "             ('ResBlock_2', (3, 16, 2)),\n",
       "             ('ResBlock_3', (3, 16, 2)),\n",
       "             ('ResBlockTransition_4', (3, 16, 32, 2)),\n",
       "             ('AvgPool2d_5', (2, 2, 0)),\n",
       "             ('Flatten', None),\n",
       "             ('Linear', (512, 10))])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet10_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional layer\n",
    "resnet10_arch[\"Conv2d_1\"] = (3, 16, 3, 1, 1)  # 32x32x3 -> 32x32x16, 3x3 kernel, stride=1, padding=1\n",
    "resnet10_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # 32x32x16 -> 16x16x16, 2x2 kernel, stride=2, padding = 0\n",
    "resnet10_arch[\"ReLU_1\"] = None\n",
    "# 2: ResBlock\n",
    "resnet10_arch[\"ResBlock_2\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 3: ResBlock\n",
    "resnet10_arch[\"ResBlock_3\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 4: ResBlock\n",
    "resnet10_arch[\"ResBlockTransition_4\"] = (3, 16, 32, 2) # 3x3 kernels, 32 in channels, 64 out channels, 2 layers\n",
    "# 5: AvgPool\n",
    "resnet10_arch[\"AvgPool2d_5\"] = (2, 2, 0) # 8x8x32 -> 4x4x32, 2x2 kernel, stride=2, padding = 0\n",
    "# 6: Flatten\n",
    "resnet10_arch[\"Flatten\"] = None  # 4x4x32 -> 512\n",
    "# 7: Fully Connected Layer\n",
    "resnet10_arch[\"Linear\"] = (512, 10) # 512 hidden units -> 10 output units\n",
    "\n",
    "resnet10_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlockTransition(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (transition): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (7): Flatten()\n",
      "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet10 = ConvNet(resnet10_arch)\n",
    "\n",
    "print(resnet10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = resnet10(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(resnet10.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.779\n",
      "[2000/6000] loss: 1.416\n",
      "[3000/6000] loss: 1.299\n",
      "[4000/6000] loss: 1.211\n",
      "[5000/6000] loss: 1.157\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.086\n",
      "[2000/6000] loss: 1.047\n",
      "[3000/6000] loss: 1.018\n",
      "[4000/6000] loss: 1.013\n",
      "[5000/6000] loss: 0.971\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.911\n",
      "[2000/6000] loss: 0.921\n",
      "[3000/6000] loss: 0.908\n",
      "[4000/6000] loss: 0.895\n",
      "[5000/6000] loss: 0.904\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(resnet10, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 68.7200 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(resnet10, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 12 for CIFAR-10\n",
    "\n",
    "Note: ResNet12 takes a little too long to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 16, 3, 1, 1)),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1', None),\n",
       "             ('ResBlock_2', (3, 16, 2)),\n",
       "             ('ResBlock_3', (3, 16, 2)),\n",
       "             ('ResBlockTransition_4', (3, 16, 32, 2)),\n",
       "             ('ResBlock_5', (3, 32, 2)),\n",
       "             ('AvgPool2d_5', (2, 2, 0)),\n",
       "             ('Flatten', None),\n",
       "             ('Linear', (512, 10))])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet12_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolutional layer\n",
    "resnet12_arch[\"Conv2d_1\"] = (3, 16, 3, 1, 1)  # 32x32x3 -> 32x32x16, 3x3 kernel, stride=1, padding=1\n",
    "resnet12_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # 32x32x16 -> 16x16x16, 2x2 kernel, stride=2, padding = 0\n",
    "resnet12_arch[\"ReLU_1\"] = None\n",
    "# 2: ResBlock\n",
    "resnet12_arch[\"ResBlock_2\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 3: ResBlock\n",
    "resnet12_arch[\"ResBlock_3\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 4: ResBlock\n",
    "resnet12_arch[\"ResBlockTransition_4\"] = (3, 16, 32, 2) # 3x3 kernels, 32 in channels, 64 out channels, 2 layers\n",
    "# 5: ResBlock\n",
    "resnet12_arch[\"ResBlock_5\"] = (3, 32, 2) # 3x3 kernels, 32 channels, 2 layers\n",
    "# 6: AvgPool\n",
    "resnet12_arch[\"AvgPool2d_5\"] = (2, 2, 0) # 8x8x32 -> 4x4x32, 2x2 kernel, stride=2, padding = 0\n",
    "# 7: Flatten\n",
    "resnet12_arch[\"Flatten\"] = None  # 4x4x32 -> 512\n",
    "# 8: Fully Connected Layer\n",
    "resnet12_arch[\"Linear\"] = (512, 10) # 512 hidden units -> 10 output units\n",
    "\n",
    "resnet12_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlockTransition(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (transition): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (8): Flatten()\n",
      "    (9): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet12 = ConvNet(resnet12_arch)\n",
    "\n",
    "print(resnet12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = resnet12(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(resnet12.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.786\n",
      "[2000/6000] loss: 1.481\n",
      "[3000/6000] loss: 1.334\n",
      "[4000/6000] loss: 1.242\n",
      "[5000/6000] loss: 1.168\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.076\n",
      "[2000/6000] loss: 1.053\n",
      "[3000/6000] loss: 1.034\n",
      "[4000/6000] loss: 1.027\n",
      "[5000/6000] loss: 0.976\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.914\n",
      "[2000/6000] loss: 0.904\n",
      "[3000/6000] loss: 0.919\n",
      "[4000/6000] loss: 0.903\n",
      "[5000/6000] loss: 0.880\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(resnet12, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 67.9800 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(resnet12, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d_1', (3, 16, 3, 1, 1)),\n",
       "             ('MaxPool2d_1', (2, 2, 0)),\n",
       "             ('ReLU_1', None),\n",
       "             ('ResBlock_2', (3, 16, 2)),\n",
       "             ('ResBlock_3', (3, 16, 2)),\n",
       "             ('ResBlockTransition_4', (3, 16, 32, 2)),\n",
       "             ('AvgPool2d_5', (2, 2, 0)),\n",
       "             ('Flatten_6', None),\n",
       "             ('Linear_1', (512, 256)),\n",
       "             ('Linear_2', (256, 10))])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_fc_arch = OrderedDict()\n",
    "\n",
    "# 1: Convolresnet_fcutional layer\n",
    "resnet_fc_arch[\"Conv2d_1\"] = (3, 16, 3, 1, 1)  # 32x32x3 -> 32x32x16, 3x3 kernel, stride=1, padding=1\n",
    "resnet_fc_arch[\"MaxPool2d_1\"] = (2, 2, 0)  # 32x32x16 -> 16x16x16, 2x2 kernel, stride=2, padding = 0\n",
    "resnet_fc_arch[\"ReLU_1\"] = None\n",
    "# 2: ResBlock\n",
    "resnet_fc_arch[\"ResBlock_2\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 3: ResBlock\n",
    "resnet_fc_arch[\"ResBlock_3\"] = (3, 16, 2) # 3x3 kernels, 16 channels, 2 layers\n",
    "# 4: ResBlock\n",
    "resnet_fc_arch[\"ResBlockTransition_4\"] = (3, 16, 32, 2) # 3x3 kernels, 32 in channels, 64 out channels, 2 layers\n",
    "# 5: AvgPool\n",
    "resnet_fc_arch[\"AvgPool2d_5\"] = (2, 2, 0) # 8x8x32 -> 4x4x32, 2x2 kernel, stride=2, padding = 0\n",
    "# 6: Flatten\n",
    "resnet_fc_arch[\"Flatten_6\"] = None  # 4x4x32 -> 512\n",
    "# 7: Fully Connected Layer\n",
    "resnet_fc_arch[\"Linear_1\"] = (512, 256) # 512 hidden units -> 256 hidden units\n",
    "# 7: Fully Connected Layer\n",
    "resnet_fc_arch[\"Linear_2\"] = (256, 10) # 256 hidden units -> 10 hidden units\n",
    "\n",
    "resnet_fc_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlockTransition(\n",
      "      (convolution_block): ModuleList(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (transition): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (7): Flatten()\n",
      "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (9): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet_fc = ConvNet(resnet_fc_arch)\n",
    "\n",
    "print(resnet_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "y = resnet_fc(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(resnet_fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ================================================================================>\n",
      "[1000/6000] loss: 1.727\n",
      "[2000/6000] loss: 1.422\n",
      "[3000/6000] loss: 1.301\n",
      "[4000/6000] loss: 1.195\n",
      "[5000/6000] loss: 1.176\n",
      "Epoch: 2 ================================================================================>\n",
      "[1000/6000] loss: 1.092\n",
      "[2000/6000] loss: 1.063\n",
      "[3000/6000] loss: 1.024\n",
      "[4000/6000] loss: 1.021\n",
      "[5000/6000] loss: 1.003\n",
      "Epoch: 3 ================================================================================>\n",
      "[1000/6000] loss: 0.923\n",
      "[2000/6000] loss: 0.924\n",
      "[3000/6000] loss: 0.923\n",
      "[4000/6000] loss: 0.936\n",
      "[5000/6000] loss: 0.931\n",
      "Finished Training =======================================================================>\n"
     ]
    }
   ],
   "source": [
    "train(resnet_fc, cifar10_trainloader, adam, cross_entropy, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 10000 test images: 65.8000 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(resnet10, cifar10_testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (axiom)\n",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
